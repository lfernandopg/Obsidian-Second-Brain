---
fileClass: resource
type: üí¨ Prompt
referenceStatus: ‚ö™Ô∏è Inbox
creationStatus:
source: "[[Local Machine]]"
location: üìù Obsidian Note
author: "[[Luis Fernando Pe√±a (Me)]]"
tags:
url:
areas:
projects:
tasks:
resources: "[[Untitled]]"
aliases:
createdDate: Oct 20, 2025 - 08:42
modifiedDate: Oct 20, 2025 - 08:59
favorite: false
archived: false
---
---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos, necesito que hagas una busqueda extensa de articulos en arxiv y google scholar, aproximadamente 20 articulos, y poder realizar el primer capitulo el cual es el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con ML a lo largo del tiempo hasta la fecha, que tecnicas se usaron, modelos, sus metricas, desafios entre otros. ¬øQu√© t√©cnicas se usaban antes del auge del Machine Learning moderno?
¬øCu√°les fueron los primeros enfoques de Machine Learning aplicados al problema? (Probablemente modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica), ¬øCuales son los enfoques mas actuales?. Representaci√≥n del Texto, Datasets Utilizados.
Toda la investigacion debe estar respaldada por articulos cientificos. 

El capitulo se puede organizar de la siguiente manera:

Primeros Enfoques y M√©todos Tradicionales (Sentando las Bases)
* Basado en tus art√≠culos m√°s antiguos, describe c√≥mo se abordaba inicialmente el problema.
* ¬øSe usaban reglas manuales o enfoques basados en diccionarios?
* ¬øCu√°les fueron las primeras t√©cnicas de Machine Learning aplicada?
* Menciona los resultados t√≠picos o las limitaciones de estos enfoques iniciales seg√∫n los papers.

La Era del Deep Learning y Embeddings (Evoluci√≥n de las T√©cnicas)
* Aqu√≠ es donde muestras el cambio hacia modelos m√°s complejos.
* Describe el impacto de los Word Embeddings (Word2Vec, GloVe) y c√≥mo mejoraron la representaci√≥n del texto.
* Presenta el uso de Redes Neuronales (CNNs, RNNs, LSTMs, GRUs) para este problema. Explica por qu√© fueron una mejora (capturan secuencias, contexto local/global).
* Para los art√≠culos relevantes en esta secci√≥n, describe el modelo DL usado, el tipo de embeddings, los datasets y las m√©tricas clave reportadas.

El Impacto de los Modelos Pre-entrenados y Transformers (Estado del Arte Actual)
* Discute c√≥mo modelos grandes pre-entrenados como BERT, RoBERTa, y sus adaptaciones (Ej: HateBERT) han transformado el campo.
* Por qu√© estos modelos son tan potentes.
* Detalla los enfoques basados en Transformers encontrados en tus art√≠culos m√°s recientes.
* Para estos papers, menciona los modelos espec√≠ficos (BERT, etc.), c√≥mo los adaptaron, los datasets m√°s recientes y los resultados de rendimiento de vanguardia (utilizando las m√©tricas relevantes).
---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar, aproximadamente 20 articulos, y poder realizar el primer capitulo el cual es el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con ML a lo largo del tiempo hasta la fecha, que tecnicas se usaron, modelos, sus metricas, desafios entre otros. ¬øQu√© t√©cnicas se usaban antes del auge del Machine Learning moderno?
¬øCu√°les fueron los primeros enfoques de Machine Learning aplicados al problema? (Probablemente modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, KNN, SGDClassifier, Random Forest), ¬øCuales son los enfoques mas actuales?. Representaci√≥n del Texto, Datasets Utilizados.
Toda la investigacion debe estar respaldada por articulos cientificos. 

Aqu√≠ tienes una estructura para el Cap√≠tulo 1 (Estado del Arte):

- Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")
* Esta es la secci√≥n principal donde describes la trayectoria de la investigaci√≥n.
* No necesitas explicar qu√© es un SVM o un Transformer aqu√≠ (eso va en el Marco Te√≥rico). En cambio, describe c√≥mo se aplicaron al problema de la detecci√≥n de discurso de odio y qu√© resultados se obtuvieron.

- Enfoques Tempranos y Basados en Reglas/Diccionarios: Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple. 

- Aplicaciones Iniciales de Machine Learning Tradicional: ¬øC√≥mo se usaron SVM, Naive Bayes, etc.? ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos? (Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF).

- Integraci√≥n de Word Embeddings y Modelos Neuronales Simples: Describe el impacto de los embeddings y c√≥mo se combinaron con CNNs o RNNs b√°sicas.

- Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n: Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas.

- El Paradigma de los Modelos Pre-entrenados (Transformers): Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.
* Dentro de cada sub-secci√≥n, menciona los modelos espec√≠ficos aplicados, los datasets clave utilizados en esos trabajos particulares, las m√©tricas reportadas y los resultados obtenidos. Compara y contrasta si los art√≠culos lo permiten.

- Datasets y Desaf√≠os Asociados a los Datos
* Discute los principales datasets que aparecen en la literatura revisada.
* Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).
* Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.

- M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura
* Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.
* Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?
* Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.

- Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")
* Esta secci√≥n es CRUCIAL para justificar tu propuesta.
* Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.
* Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.
* Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.
---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar (mayoritariamente arvix), aproximadamente 20 articulos o mas, y poder realizar el primer capitulo el cual es el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con ML a lo largo del tiempo hasta la fecha, que tecnicas se usaron, modelos, sus metricas, desafios entre otros. ¬øQu√© t√©cnicas se usaban antes del auge del Machine Learning moderno?
¬øCu√°les fueron los primeros enfoques de Machine Learning aplicados al problema? (Probablemente modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, KNN, SGDClassifier, Random Forest), ¬øCuales son los enfoques mas actuales?. Representaci√≥n del Texto, Datasets Utilizados.

Toda la investigacion debe estar respaldada por articulos cientificos. 

Aqu√≠ tienes una estructura para el Cap√≠tulo 1 (Estado del Arte):

- Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")
* Esta es la secci√≥n principal donde describes la trayectoria de la investigaci√≥n.
* No necesitas explicar qu√© es un SVM o un Transformer aqu√≠ (eso va en el Marco Te√≥rico). En cambio, describe c√≥mo se aplicaron al problema de la detecci√≥n de discurso de odio y qu√© resultados se obtuvieron.

- Enfoques Tempranos y Basados en Reglas/Diccionarios: Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple. 

- Aplicaciones Iniciales de Machine Learning Tradicional: ¬øC√≥mo se usaron SVM, Naive Bayes, etc.? ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos? (Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF).

- Integraci√≥n de Word Embeddings y Modelos Neuronales Simples: Describe el impacto de los embeddings y c√≥mo se combinaron con CNNs o RNNs b√°sicas.

- Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n: Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas.

- El Paradigma de los Modelos Pre-entrenados (Transformers): Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.
* Dentro de cada sub-secci√≥n, menciona los modelos espec√≠ficos aplicados, los datasets clave utilizados en esos trabajos particulares, las m√©tricas reportadas y los resultados obtenidos. Compara y contrasta si los art√≠culos lo permiten.

- Datasets y Desaf√≠os Asociados a los Datos
* Discute los principales datasets que aparecen en la literatura revisada.
* Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).
* Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.

- M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura
* Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.
* Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?
* Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.

- Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")
* Esta secci√≥n es CRUCIAL para justificar tu propuesta.
* Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.
* Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.
* Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.

-Conclusiones del Cap√≠tulo
* Resume brevemente los hallazgos clave de la revisi√≥n: la trayectoria del campo, las t√©cnicas m√°s destacadas, el estado actual, y reitera los principales desaf√≠os y las oportunidades de investigaci√≥n.
* Concluye indicando que el siguiente cap√≠tulo (Marco Te√≥rico) proporcionar√° los fundamentos te√≥ricos necesarios para comprender las bases de estos enfoques y la metodolog√≠a a seguir.
---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que realices el primer capitulo el cual es el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con ML a lo largo del tiempo hasta la fecha, que tecnicas se usaron, modelos, sus metricas, desafios entre otros. ¬øQu√© t√©cnicas se usaban antes del auge del Machine Learning moderno?
¬øCu√°les fueron los primeros enfoques de Machine Learning aplicados al problema? (Probablemente modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, KNN, SGDClassifier, Random Forest), ¬øCuales son los enfoques mas actuales?. Representaci√≥n del Texto, Datasets Utilizados.


Aqu√≠ tienes una estructura para el Cap√≠tulo 1 (Estado del Arte):

- Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")
* Esta es la secci√≥n principal donde describes la trayectoria de la investigaci√≥n.
* No necesitas explicar qu√© es un SVM o un Transformer aqu√≠ (eso va en el Marco Te√≥rico). En cambio, describe c√≥mo se aplicaron al problema de la detecci√≥n de discurso de odio y qu√© resultados se obtuvieron.

- Enfoques Tempranos y Basados en Reglas/Diccionarios: Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple. 

- Aplicaciones Iniciales de Machine Learning Tradicional: ¬øC√≥mo se usaron SVM, Naive Bayes, etc.? ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos? (Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF).

- Integraci√≥n de Word Embeddings y Modelos Neuronales Simples: Describe el impacto de los embeddings y c√≥mo se combinaron con CNNs o RNNs b√°sicas.

- Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n: Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas.

- El Paradigma de los Modelos Pre-entrenados (Transformers): Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.
* Dentro de cada sub-secci√≥n, menciona los modelos espec√≠ficos aplicados, los datasets clave utilizados en esos trabajos particulares, las m√©tricas reportadas y los resultados obtenidos. Compara y contrasta si los art√≠culos lo permiten.

- Datasets y Desaf√≠os Asociados a los Datos
* Discute los principales datasets que aparecen en la literatura revisada.
* Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).
* Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.

- M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura
* Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.
* Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?
* Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.

- Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")
* Esta secci√≥n es CRUCIAL para justificar tu propuesta.
* Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.
* Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.
* Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.

-Conclusiones del Cap√≠tulo
* Resume brevemente los hallazgos clave de la revisi√≥n: la trayectoria del campo, las t√©cnicas m√°s destacadas, el estado actual, y reitera los principales desaf√≠os y las oportunidades de investigaci√≥n.
* Concluye indicando que el siguiente cap√≠tulo (Marco Te√≥rico) proporcionar√° los fundamentos te√≥ricos necesarios para comprender las bases de estos enfoques y la metodolog√≠a a seguir.
---
Cap√≠tulo 1: Estado del Arte - Detecci√≥n del Discurso de Odio con Machine Learning- Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")

Enfoques Tempranos y Basados en Reglas/Diccionarios: Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple.Antes de la generalizaci√≥n del aprendizaje autom√°tico, la detecci√≥n del discurso de odio se basaba principalmente en sistemas basados en reglas y diccionarios de t√©rminos ofensivos.1 Estos enfoques iniciales implicaban la creaci√≥n manual de listas de palabras clave y patrones que se consideraban indicativos de discurso de odio.3 Por ejemplo, un sistema pod√≠a marcar cualquier texto que contuviera insultos espec√≠ficos o t√©rminos despectivos.2 Estos sistemas ofrec√≠an la ventaja de ser intuitivos y personalizables 4, lo que facilitaba a los humanos la comprensi√≥n de por qu√© se se√±alaba cierto contenido.7 Tambi√©n pod√≠an adaptarse a tipos espec√≠ficos de discurso de odio mediante la adici√≥n de palabras clave relevantes.1 La sencillez de estos sistemas permit√≠a un control directo sobre el proceso de detecci√≥n. Si un t√©rmino espec√≠fico se consideraba odioso, pod√≠a a√±adirse inmediatamente al diccionario. Esta correspondencia directa entre las palabras clave y la clasificaci√≥n hac√≠a que la l√≥gica del sistema fuera transparente.
Sin embargo, estos m√©todos presentaban limitaciones significativas.3 A menudo eran fr√°giles y carec√≠an de la flexibilidad necesaria para manejar los matices del lenguaje, como el sarcasmo, la iron√≠a o las palabras clave utilizadas para evadir la detecci√≥n.8 Los usuarios pod√≠an sortear f√°cilmente estos sistemas deletreando mal las palabras o utilizando sin√≥nimos.2 La naturaleza est√°tica de los diccionarios y las reglas los hac√≠a susceptibles a la naturaleza evolutiva del discurso de odio.9 Con el tiempo surgen nuevos insultos y expresiones de odio, lo que requiere actualizaciones manuales constantes del sistema.11 El lenguaje es din√°mico y el discurso de odio se adapta para evitar la censura. Los sistemas basados en reglas, que se basan en patrones predefinidos, tienen dificultades para seguir el ritmo de esta evoluci√≥n. La necesidad de una intervenci√≥n humana continua para actualizar estas reglas hace que el proceso sea ineficiente y potencialmente incompleto.
Adem√°s, estos sistemas a menudo sufr√≠an de baja precisi√≥n, marcando como discurso de odio lenguaje ofensivo o incluso texto neutral que conten√≠a las palabras clave, sin considerar el contexto.5 El contexto es crucial para determinar si un fragmento de texto constituye discurso de odio.5 Los sistemas basados en reglas, que se centran √∫nicamente en la presencia de ciertas palabras, a menudo no tienen en cuenta las palabras circundantes y la intenci√≥n general del mensaje.5 Una palabra que se considera un insulto en un contexto puede utilizarse de forma inocua o incluso ser reclamada por el grupo al que se dirige en otro.9 Los sistemas basados en reglas carecen de la comprensi√≥n sem√°ntica para diferenciar estos casos, lo que lleva a clasificaciones inexactas.


Aplicaciones Iniciales de Machine Learning Tradicional: ¬øC√≥mo se usaron SVM, Naive Bayes, etc.? ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos? (Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF).Las limitaciones de los sistemas basados en reglas llevaron a la adopci√≥n de los primeros modelos de aprendizaje autom√°tico para la detecci√≥n del discurso de odio.1 Algoritmos como las M√°quinas de Vectores de Soporte (SVM), Naive Bayes y la Regresi√≥n Log√≠stica fueron de los primeros en aplicarse a este problema.13 Estos modelos ofrec√≠an la ventaja de aprender patrones a partir de los datos, lo que potencialmente les permit√≠a capturar formas m√°s matizadas de discurso de odio en comparaci√≥n con los r√≠gidos sistemas basados en reglas.1 En lugar de depender de reglas expl√≠citas, estos modelos de ML pod√≠an aprender las relaciones estad√≠sticas entre las palabras y la etiqueta de discurso de odio a partir de un conjunto de datos de entrenamiento. Este enfoque basado en datos permit√≠a una detecci√≥n m√°s adaptativa y potencialmente m√°s precisa.
Estos modelos tradicionalmente depend√≠an de t√©cnicas de ingenier√≠a de caracter√≠sticas para convertir el texto en representaciones num√©ricas que los algoritmos pudieran procesar.5 Dos m√©todos comunes de extracci√≥n de caracter√≠sticas fueron la Frecuencia de T√©rmino-Frecuencia Inversa de Documento (TF-IDF) y los n-gramas.5 El TF-IDF se utilizaba para ponderar la importancia de las palabras en un documento en relaci√≥n con una colecci√≥n de documentos. Las palabras que aparec√≠an con frecuencia en un texto espec√≠fico pero raramente en otros se consideraban m√°s significativas para la clasificaci√≥n.5 Por ejemplo, los insultos de odio espec√≠ficos probablemente tendr√≠an una puntuaci√≥n TF-IDF alta en los textos de discurso de odio.17 Los n-gramas implicaban considerar secuencias de n palabras (o caracteres) como caracter√≠sticas.5 Los unigramas (palabras individuales), los bigramas (secuencias de dos palabras) y los trigramas (secuencias de tres palabras) se utilizaban a menudo para capturar cierta informaci√≥n contextual.5 Por ejemplo, el bigrama "I hate" seguido de un grupo espec√≠fico podr√≠a ser un fuerte indicador de discurso de odio.13
SVM, por ejemplo, se utilizaba con caracter√≠sticas TF-IDF y n-gramas para encontrar un hiperplano √≥ptimo que separara el discurso de odio del que no lo es.7 Los estudios mostraron resultados prometedores, con SVM a menudo superando a otros modelos tradicionales de ML en t√©rminos de precisi√≥n y puntuaci√≥n F1.13 Por ejemplo, un estudio encontr√≥ que las caracter√≠sticas de bigramas combinadas con SVM alcanzaron una precisi√≥n del 79%.13 Otro estudio que utilizaba TF-IDF con un modelo SGD logr√≥ una alta precisi√≥n del 98,21% en el discurso de odio en √°rabe.17 Naive Bayes, un clasificador probabil√≠stico, tambi√©n se aplic√≥, a menudo con caracter√≠sticas TF-IDF, para predecir la probabilidad de que un texto perteneciera a la clase de discurso de odio.13 Algunos estudios informaron de un buen rendimiento con Naive Bayes, alcanzando precisiones en torno al 87%.12 La regresi√≥n log√≠stica, un modelo lineal, fue otro enfoque temprano, a menudo utilizado con caracter√≠sticas de n-gramas.14 Proporcionaba una puntuaci√≥n de probabilidad para la clasificaci√≥n y era relativamente f√°cil de interpretar.14 Un estudio que utilizaba la regresi√≥n log√≠stica con n-gramas logr√≥ una puntuaci√≥n F1 de 0,824.22 El rendimiento de estos primeros modelos de ML depend√≠a en gran medida de la calidad de las caracter√≠sticas dise√±adas.13 La elaboraci√≥n de caracter√≠sticas eficaces requer√≠a experiencia en el dominio y una cuidadosa experimentaci√≥n.5 La capacidad de estos modelos para detectar el discurso de odio estaba limitada por lo bien que las caracter√≠sticas artesanales pod√≠an capturar los patrones complejos y los matices del lenguaje odioso. Si las caracter√≠sticas no eran exhaustivas o no representaban informaci√≥n contextual importante, el rendimiento del modelo se ver√≠a afectado.


Integraci√≥n de Word Embeddings y Modelos Neuronales Simples: Describe el impacto de los embeddings y c√≥mo se combinaron con CNNs o RNNs b√°sicas.La introducci√≥n de los word embeddings marc√≥ un avance significativo en la representaci√≥n textual para la detecci√≥n del discurso de odio.10 Los word embeddings, como Word2Vec, GloVe y FastText, aprendieron representaciones vectoriales densas de las palabras bas√°ndose en su contexto en grandes cantidades de datos de texto.10 Las palabras sem√°nticamente similares estaban representadas por vectores cercanos entre s√≠ en el espacio de embedding.10 Los word embeddings permitieron a los modelos capturar relaciones sem√°nticas entre palabras, yendo m√°s all√° del enfoque de bolsa de palabras de TF-IDF y n-gramas.10 Esto permiti√≥ a los modelos comprender mejor el significado y la intenci√≥n detr√°s del texto.19 A diferencia de TF-IDF, que trata las palabras como entidades independientes, los word embeddings capturan el significado contextual de las palabras. Esto significa que un modelo que utiliza word embeddings podr√≠a entender potencialmente que "est√∫pido" e "idiota" son similares en significado y que ambos podr√≠an utilizarse en contextos odiosos.
Estos word embeddings se integraron entonces con arquitecturas de redes neuronales simples como las Redes Neuronales Convolucionales (CNN) y las Redes Neuronales Recurrentes (RNN) para la clasificaci√≥n del discurso de odio.23 Las CNN, inicialmente populares en visi√≥n por computador, se adaptaron para tareas de PNL tratando el texto como una secuencia unidimensional.23 Utilizaban filtros convolucionales para aprender patrones locales de palabras que eran indicativos de discurso de odio.27 Por ejemplo, una CNN podr√≠a aprender a reconocer frases odiosas espec√≠ficas o combinaciones de palabras.28 Los estudios demostraron que las CNN combinadas con word embeddings pod√≠an lograr un buen rendimiento, y un estudio inform√≥ de una puntuaci√≥n F1 macro ponderada de 0,66 con word embeddings de GloVe.25 Las RNN, en particular las redes de memoria a corto plazo (LSTM) y las unidades recurrentes cerradas (GRU), se dise√±aron para procesar datos secuenciales y pod√≠an capturar dependencias entre palabras en una frase.23 Las LSTM y las GRU pod√≠an recordar informaci√≥n de partes anteriores de la frase, lo que les permit√≠a comprender mejor el contexto.27 Un estudio que utilizaba word embeddings espec√≠ficos del dominio con un modelo BiLSTM logr√≥ una puntuaci√≥n F1 del 93%.10 La combinaci√≥n de word embeddings con redes neuronales permiti√≥ a los modelos aprender autom√°ticamente caracter√≠sticas relevantes de los datos de texto, lo que redujo la necesidad de una extensa ingenier√≠a manual de caracter√≠sticas.23 En lugar de depender de los humanos para definir qu√© caracter√≠sticas son importantes, estas redes neuronales pod√≠an aprender las representaciones √≥ptimas directamente de los datos. Este enfoque de aprendizaje de extremo a extremo ten√≠a el potencial de descubrir patrones m√°s complejos y sutiles en el discurso de odio.


Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n: Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas.Para capturar dependencias m√°s complejas y de largo alcance en el texto, los investigadores comenzaron a utilizar arquitecturas de redes neuronales recurrentes m√°s avanzadas, como las LSTM y las GRU, con mecanismos de atenci√≥n.29 Las LSTM y las GRU se desarrollaron a√∫n m√°s para abordar el problema de la desaparici√≥n del gradiente en las RNN b√°sicas, lo que les permiti√≥ recordar informaci√≥n durante secuencias de palabras m√°s largas.23 Esto fue crucial para comprender el contexto en publicaciones de redes sociales m√°s largas.27 Los mecanismos de atenci√≥n permitieron al modelo ponderar la importancia de diferentes palabras en la secuencia de entrada al realizar una predicci√≥n.29 Esto significaba que el modelo pod√≠a centrarse en las partes m√°s relevantes del texto al determinar si conten√≠a discurso de odio.29 Por ejemplo, en una frase como "Odio a todos estos [t√©rmino ofensivo para un grupo]", el mecanismo de atenci√≥n probablemente se centrar√≠a en "odio" y el t√©rmino ofensivo.
Los estudios demostraron que las LSTM y las GRU con atenci√≥n superaban a las redes neuronales m√°s simples y a los modelos tradicionales de ML.29 Por ejemplo, un estudio propuso una red neuronal LSTM+MLP que logr√≥ un AUC de 0,828 en un conjunto de datos de discurso de odio en espa√±ol.7 Otro estudio que utilizaba BiLSTMs con atenci√≥n inform√≥ de buenos resultados en la detecci√≥n de discurso de odio en urdu romano.35 Los mecanismos de atenci√≥n mejoraron significativamente la capacidad de las redes recurrentes para manejar secuencias largas y centrarse en las palabras m√°s importantes para la clasificaci√≥n.29 Al permitir que el modelo atienda selectivamente a diferentes partes del texto de entrada, los mecanismos de atenci√≥n permitieron al modelo comprender mejor el contexto e identificar se√±ales sutiles de discurso de odio que podr√≠an pasar desapercibidas si el texto se procesara simplemente de forma secuencial.


El Paradigma de los Modelos Pre-entrenados (Transformers): Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.La llegada de los modelos basados en transformadores, como BERT, RoBERTa y sus variantes, revolucion√≥ el campo de la detecci√≥n del discurso de odio.10 Estos modelos se basan en la arquitectura del transformador, que utiliza mecanismos de autoatenci√≥n para comprender el contexto de las palabras en una frase considerando todas las dem√°s palabras simult√°neamente.39 Los modelos de transformadores sobresalen en la captura de dependencias de largo alcance y en la comprensi√≥n del contexto de las palabras de una manera que las arquitecturas anteriores ten√≠an dificultades.39 Esta profunda comprensi√≥n contextual es crucial para detectar con precisi√≥n el discurso de odio, que a menudo se basa en se√±ales sutiles y significados impl√≠citos.43 A diferencia de las RNN que procesan el texto secuencialmente, los transformadores pueden procesar todas las palabras de una frase a la vez, lo que les permite aprender directamente las relaciones entre las palabras independientemente de su distancia en la frase. Esto es particularmente beneficioso para comprender frases complejas donde el significado depende de palabras que est√°n muy separadas.
El enfoque t√≠pico para aplicar estos modelos a la detecci√≥n del discurso de odio es mediante el ajuste fino. Los modelos de transformadores preentrenados, que han sido entrenados en grandes cantidades de datos de texto, se adaptan a la tarea espec√≠fica de clasificaci√≥n del discurso de odio utilizando conjuntos de datos etiquetados de discurso de odio.36 Este enfoque de aprendizaje por transferencia permite a estos modelos lograr resultados de vanguardia con cantidades relativamente peque√±as de datos espec√≠ficos de la tarea.39 El preentrenamiento en grandes corpus proporciona a los modelos de transformadores una s√≥lida comprensi√≥n del lenguaje general, que luego puede transferirse eficazmente a la tarea de detecci√≥n del discurso de odio mediante el ajuste fino.39 La fase de preentrenamiento permite al modelo aprender patrones y representaciones ling√º√≠sticas generales. El ajuste fino adapta entonces estas representaciones generales a las caracter√≠sticas espec√≠ficas del discurso de odio, lo que lleva a un alto rendimiento incluso con datos etiquetados limitados para la tarea del discurso de odio.
Los estudios han demostrado consistentemente que los modelos de transformadores superan a los enfoques anteriores en varios puntos de referencia de detecci√≥n de discurso de odio.35 Por ejemplo, BERT y sus variantes han logrado alta precisi√≥n y puntuaciones F1 en conjuntos de datos en m√∫ltiples idiomas.35 Los m√©todos de conjunto que combinan m√∫ltiples modelos de transformadores tambi√©n han mostrado resultados prometedores.36 El √©xito de los modelos de transformadores los ha convertido en el paradigma dominante en la investigaci√≥n de la detecci√≥n del discurso de odio.9 Los investigadores contin√∫an explorando diferentes arquitecturas de transformadores, estrategias de preentrenamiento y t√©cnicas de ajuste fino para mejorar a√∫n m√°s el rendimiento y abordar los desaf√≠os restantes.37 El campo est√° en constante evoluci√≥n con nuevos modelos y t√©cnicas basados en transformadores que se est√°n desarrollando. Esta investigaci√≥n en curso tiene como objetivo abordar las limitaciones de los modelos actuales, como el sesgo, la falta de explicabilidad y la dificultad para detectar formas sutiles de discurso de odio.

- Datasets y Desaf√≠os Asociados a los Datos

Discute los principales datasets que aparecen en la literatura revisada.


Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).


Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.Se han creado numerosos conjuntos de datos para la investigaci√≥n sobre la detecci√≥n del discurso de odio.24 Estos conjuntos de datos var√≠an significativamente en su fuente (por ejemplo, Twitter, Facebook, YouTube, Reddit, foros en l√≠nea) 5, idioma (principalmente ingl√©s, pero tambi√©n alem√°n, espa√±ol, √°rabe, hindi, etc.) 44, tama√±o (desde unos pocos miles hasta millones de publicaciones) 5 y esquemas de etiquetado (binario: odio/no odio; multiclase: odio, ofensivo, normal; o categor√≠as m√°s detalladas).5 Algunos conjuntos de datos destacados incluyen el Conjunto de Datos para la Identificaci√≥n de Lenguaje Ofensivo (OLID) 73, HASOC (Identificaci√≥n de Discurso de Odio y Contenido Ofensivo en Lenguas Indo-Europeas) 42 y los conjuntos de datos de Waseem y Hovy.88 La diversidad de conjuntos de datos refleja la naturaleza multifac√©tica del discurso de odio y los diferentes contextos en los que se manifiesta.69 Sin embargo, esta diversidad tambi√©n plantea desaf√≠os para comparar el rendimiento de diferentes modelos y generalizar los hallazgos entre plataformas e idiomas.56 Los modelos entrenados en un conjunto de datos pueden no funcionar bien en otro debido a las diferencias en la definici√≥n de discurso de odio, los grupos objetivo, el idioma utilizado y la forma en que se recopilaron y anotaron los datos. Esta falta de estandarizaci√≥n dificulta la evaluaci√≥n del verdadero progreso en el campo.
Un desaf√≠o importante asociado con estos conjuntos de datos es el desequilibrio de clases, donde el n√∫mero de instancias de discurso de odio es t√≠picamente mucho menor que el n√∫mero de instancias de discurso no odioso.5 Este desequilibrio puede llevar a modelos que est√°n sesgados hacia la clase mayoritaria y que tienen un rendimiento deficiente en la detecci√≥n del discurso de odio real.8 El desequilibrio de clases es un problema cr√≠tico que debe abordarse para construir modelos eficaces de detecci√≥n del discurso de odio.69 La precisi√≥n por s√≠ sola no es una m√©trica suficiente en tales casos, ya que un modelo que siempre predice "no discurso de odio" podr√≠a lograr una alta precisi√≥n si el desequilibrio es severo.9 Cuando la clase mayoritaria supera significativamente a la minoritaria, un modelo puede lograr una alta precisi√≥n simplemente aprendiendo a predecir la clase mayoritaria la mayor parte del tiempo. Esto no significa que el modelo sea bueno para detectar la clase minoritaria (discurso de odio), que es el objetivo principal. Por lo tanto, m√©tricas como la precisi√≥n, la exhaustividad y la puntuaci√≥n F1 son m√°s importantes para evaluar el rendimiento en conjuntos de datos desequilibrados.34
La anotaci√≥n del discurso de odio tambi√©n es muy subjetiva, lo que lleva a inconsistencias entre los anotadores y entre los conjuntos de datos.5 Lo que una persona considera discurso de odio, otra podr√≠a verlo como ofensivo o incluso aceptable.5 La naturaleza subjetiva de la anotaci√≥n del discurso de odio dificulta el establecimiento de una verdad fundamental consistente y puede introducir sesgos en los conjuntos de datos.51 Esto puede afectar la fiabilidad y la generalizaci√≥n de los modelos entrenados con dichos datos.98 Los antecedentes personales, los contextos culturales y las interpretaciones de las directrices de los anotadores pueden influir en la forma en que etiquetan el contenido. Esta variabilidad en la anotaci√≥n puede conducir a conjuntos de datos ruidosos y a modelos que aprenden estos sesgos en lugar de las caracter√≠sticas subyacentes del discurso de odio.
La calidad de los datos tambi√©n puede ser un desaf√≠o, ya que el texto de las redes sociales a menudo contiene gram√°tica no est√°ndar, errores ortogr√°ficos y abreviaturas.11 El lenguaje utilizado en l√≠nea tambi√©n est√° en constante evoluci√≥n, con nuevas jergas y expresiones que surgen con frecuencia.9 La naturaleza din√°mica y a menudo informal del lenguaje en l√≠nea dificulta que los modelos entrenados en conjuntos de datos est√°ticos se mantengan al d√≠a con las √∫ltimas formas de discurso de odio.9 Las t√©cnicas de normalizaci√≥n textual pueden ayudar a abordar algunos de estos problemas.91 Los perpetradores de discurso de odio a menudo adaptan su lenguaje para evadir la detecci√≥n, utilizando nuevos t√©rminos, abreviaturas y palabras escritas intencionalmente de forma incorrecta. Los modelos deben ser robustos a estas variaciones y actualizarse continuamente para reconocer los patrones emergentes.
Existe una necesidad significativa de conjuntos de datos de discurso de odio en diversos idiomas para abordar la naturaleza global del problema.15 La mayor√≠a de las investigaciones y los conjuntos de datos disponibles p√∫blicamente est√°n en ingl√©s, lo que lleva a modelos que pueden no ser efectivos en otros contextos ling√º√≠sticos.15 Se est√°n explorando enfoques multiling√ºes y modelos multiling√ºes para abordar este desaf√≠o.33 El enfoque predominantemente en ingl√©s de la investigaci√≥n actual crea un sesgo ling√º√≠stico y limita la aplicabilidad de los modelos desarrollados a otros idiomas y culturas.80 El desarrollo de recursos y modelos para idiomas con pocos recursos es un √°rea crucial para futuras investigaciones.15 El discurso de odio es un fen√≥meno global, y la detecci√≥n eficaz requiere modelos que puedan comprender y procesar texto en varios idiomas. Los enfoques multiling√ºes tienen como objetivo transferir el conocimiento aprendido de un idioma a otro, especialmente para los idiomas con datos etiquetados limitados.
Tabla 1: Caracter√≠sticas de los Principales Conjuntos de Datos

Nombre del DatasetFuenteIdioma(s)Tama√±o (Instancias)Esquema de EtiquetadoCaracter√≠sticas NotablesOLIDTwitterIngl√©s> 14,000Ofensivo/No, Dirigido/No, Individuo/Grupo/OtroAnotaci√≥n Jer√°rquicaHASOCTwitter, FacebookIngl√©s, Hindi, Alem√°n> 5,000 por idiomaOdio/No, Ofensivo, ProfanoMultiling√ºeWaseem y HovyTwitterIngl√©s~ 16,000Sexista, Racista, NingunoSesgo de Usuario- M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura

Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.


Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?


Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.El rendimiento de los modelos de detecci√≥n del discurso de odio se eval√∫a t√≠picamente utilizando varias m√©tricas.5 Las m√©tricas comunes incluyen la Precisi√≥n (Accuracy), la Exactitud (Precision), la Exhaustividad (Recall), la Puntuaci√≥n F1 (F1-score) y el √Årea Bajo la Curva Caracter√≠stica Operativa del Receptor (AUC).5 La Precisi√≥n mide la correcci√≥n general de las predicciones del modelo (la proporci√≥n de instancias clasificadas correctamente con respecto al n√∫mero total de instancias).34 La Exactitud mide la proporci√≥n de instancias de discurso de odio identificadas correctamente entre todas las instancias clasificadas como discurso de odio (minimizando los falsos positivos).34 La Exhaustividad mide la proporci√≥n de instancias reales de discurso de odio que fueron identificadas correctamente por el modelo (minimizando los falsos negativos).34 La Puntuaci√≥n F1 es la media arm√≥nica de la exactitud y la exhaustividad, lo que proporciona una medida equilibrada del rendimiento del modelo, especialmente √∫til cuando se trata de conjuntos de datos desequilibrados.34 El AUC representa el √°rea bajo la curva ROC, que traza la tasa de verdaderos positivos (exhaustividad) contra la tasa de falsos positivos en varios ajustes de umbral.34 Proporciona una medida general de la capacidad del modelo para discriminar entre las dos clases.
Dado el significativo desequilibrio de clases en los conjuntos de datos de detecci√≥n de discurso de odio, la precisi√≥n por s√≠ sola a menudo no es una m√©trica suficiente para evaluar el rendimiento del modelo.8 Un modelo que simplemente predice la clase mayoritaria (no discurso de odio) la mayor parte del tiempo puede lograr una alta precisi√≥n, pero no detecta las instancias reales de discurso de odio.9 La exactitud y la exhaustividad son cruciales en tareas de clasificaci√≥n desequilibradas como la detecci√≥n del discurso de odio porque se centran en la capacidad del modelo para identificar correctamente la clase minoritaria (discurso de odio), que es el objetivo principal.34 La puntuaci√≥n F1 proporciona un buen equilibrio entre estas dos m√©tricas.34 En la detecci√≥n del discurso de odio, no identificar un mensaje de odio (falso negativo) puede tener graves consecuencias. La exhaustividad ayuda a medir la capacidad del modelo para evitar tales fallos. Por otro lado, se√±alar incorrectamente un mensaje inofensivo como odioso (falso positivo) tambi√©n puede ser problem√°tico, lo que lleva a la censura del discurso leg√≠timo. La exactitud mide la capacidad del modelo para evitar estos errores. La puntuaci√≥n F1 combina estos dos aspectos importantes en una sola m√©trica.
La literatura no muestra un enfoque completamente estandarizado para la evaluaci√≥n, pero el uso de las m√©tricas mencionadas (Exactitud, Exhaustividad, Puntuaci√≥n F1, AUC) es com√∫n en muchos estudios.5 Algunas tareas compartidas y conjuntos de datos de referencia, como OffensEval y HASOC, proporcionan marcos de evaluaci√≥n comunes y permiten la comparaci√≥n entre diferentes enfoques.42 Estas iniciativas ayudan a impulsar el progreso en el campo al establecer objetivos y m√©tricas comunes, facilitando una evaluaci√≥n m√°s objetiva de diferentes t√©cnicas e identificando las direcciones m√°s prometedoras para futuras investigaciones.
Tabla 2: M√©tricas de Evaluaci√≥n Comunes

M√©tricaDescripci√≥nImportancia en la Detecci√≥n del Discurso de Odio (especialmente para datos desequilibrados)Precisi√≥nProporci√≥n de instancias clasificadas correctamente como odio del total clasificadas como odio.Importante para minimizar los falsos positivos (marcar err√≥neamente contenido no odioso).ExhaustividadProporci√≥n de instancias de odio reales que fueron identificadas correctamente.Crucial para minimizar los falsos negativos (no detectar contenido odioso).Puntuaci√≥n F1Media arm√≥nica de la precisi√≥n y la exhaustividad.Proporciona una medida equilibrada del rendimiento, √∫til para datos desequilibrados.AUC√Årea bajo la curva ROC, que mide la capacidad de discriminaci√≥n del modelo.Ofrece una visi√≥n general de la capacidad del modelo para distinguir entre clases.- Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")

Esta secci√≥n es CRUCIAL para justificar tu propuesta.


Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.


Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.


Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.A pesar de los importantes avances en la detecci√≥n del discurso de odio mediante el aprendizaje autom√°tico, persisten varios desaf√≠os y limitaciones.5 Detectar el sarcasmo y la iron√≠a en el texto sigue siendo un obst√°culo importante.11 Los modelos a menudo tienen dificultades para distinguir entre el discurso de odio genuino y las declaraciones sarc√°sticas o ir√≥nicas que pueden parecer odiosas en la superficie, pero tienen una intenci√≥n subyacente diferente.11 La capacidad de comprender el lenguaje figurado como el sarcasmo y la iron√≠a es crucial para la detecci√≥n precisa del discurso de odio.127 Los modelos actuales a menudo carecen del razonamiento de sentido com√∫n y la comprensi√≥n contextual necesarios para esta tarea.80 El sarcasmo y la iron√≠a a menudo se basan en un contraste entre el significado literal de las palabras y el significado pretendido. Detectar esto requiere comprender el tono, el contexto y potencialmente la intenci√≥n del hablante o autor, lo cual es un desaf√≠o complejo para la IA.
Distinguir entre el discurso de odio expl√≠cito e impl√≠cito es otro desaf√≠o continuo.68 Mientras que el discurso de odio expl√≠cito utiliza insultos directos y lenguaje odioso, el discurso de odio impl√≠cito transmite una intenci√≥n da√±ina de formas m√°s sutiles o indirectas, a menudo bas√°ndose en estereotipos, insinuaciones o lenguaje codificado.68 El discurso de odio impl√≠cito es particularmente dif√≠cil de detectar, ya que a menudo carece de las se√±ales l√©xicas obvias del discurso de odio expl√≠cito.68 Su detecci√≥n requiere una comprensi√≥n m√°s profunda del contexto social, los matices culturales y potencialmente el conocimiento hist√≥rico.131 El discurso de odio impl√≠cito a menudo explota los estereotipos y se basa en que el lector o el oyente haga inferencias da√±inas. Detectar esto requiere que el modelo tenga cierto nivel de "sentido com√∫n" y la capacidad de comprender el significado impl√≠cito m√°s all√° de las palabras literales.
La generalizaci√≥n de los modelos de detecci√≥n del discurso de odio a nuevos dominios y plataformas sigue siendo una limitaci√≥n importante.5 Los modelos entrenados con datos de una plataforma de redes sociales pueden no funcionar bien con datos de otra plataforma debido a las diferencias en el comportamiento del usuario, los estilos de lenguaje y los tipos de discurso de odio prevalentes en cada plataforma.5 La generalizaci√≥n del dominio es un desaf√≠o crucial para las aplicaciones del mundo real de la detecci√≥n del discurso de odio.5 El discurso de odio puede manifestarse de manera diferente en varios entornos en l√≠nea, y los modelos deben ser lo suficientemente robustos como para manejar estas variaciones.138 Las caracter√≠sticas del discurso de odio en una plataforma como Twitter, con su texto corto y el uso de hashtags, pueden ser diferentes de las de una plataforma como Facebook con publicaciones m√°s largas y diferentes datos demogr√°ficos de los usuarios. Los modelos deben poder adaptarse a estas caracter√≠sticas espec√≠ficas del dominio.
El sesgo en los modelos de detecci√≥n del discurso de odio es una preocupaci√≥n creciente.110 Los modelos entrenados con conjuntos de datos sesgados pueden marcar de manera desproporcionada el contenido de ciertos grupos demogr√°ficos como discurso de odio o no detectar el discurso de odio dirigido a otros grupos.110 Abordar el sesgo tanto en los conjuntos de datos como en los modelos es esencial para garantizar la equidad y prevenir da√±os no deseados.110 Esto requiere una atenci√≥n cuidadosa a las pr√°cticas de recopilaci√≥n, anotaci√≥n y entrenamiento de datos.110 Si un conjunto de datos contiene m√°s instancias de discurso de odio dirigido a un grupo que a otro, o si los anotadores son m√°s propensos a etiquetar el contenido de ciertos grupos como odioso, el modelo entrenado probablemente reflejar√° estos sesgos. Esto puede llevar a resultados injustos o discriminatorios.
La falta de explicabilidad en muchos modelos de aprendizaje profundo de vanguardia es otra limitaci√≥n.5 Comprender por qu√© un modelo clasific√≥ un fragmento de texto en particular como discurso de odio es importante para generar confianza en el sistema y para identificar y mitigar posibles sesgos.5 La Inteligencia Artificial Explicable (XAI) se est√° volviendo cada vez m√°s importante en la investigaci√≥n sobre la detecci√≥n del discurso de odio.6 Las t√©cnicas que pueden proporcionar informaci√≥n sobre el proceso de toma de decisiones del modelo son cruciales para mejorar la transparencia y la rendici√≥n de cuentas.6 Si un modelo clasifica un texto como discurso de odio, es importante comprender qu√© palabras o frases contribuyeron m√°s a esta clasificaci√≥n. Esto puede ayudar a identificar si el modelo se basa en indicadores leg√≠timos de discurso de odio o si est√° captando correlaciones espurias o sesgos.
Finalmente, la implementaci√≥n de modelos de detecci√≥n del discurso de odio en tiempo real para manejar el enorme volumen de contenido en l√≠nea plantea desaf√≠os significativos en t√©rminos de eficiencia computacional y escalabilidad.18 Los modelos deben ser lo suficientemente r√°pidos y eficientes para procesar y clasificar el contenido a medida que se genera.18 La detecci√≥n del discurso de odio en tiempo real requiere un equilibrio entre la precisi√≥n del modelo y la eficiencia computacional.18 Los modelos complejos de aprendizaje profundo, aunque a menudo logran una alta precisi√≥n, pueden ser computacionalmente costosos y pueden no ser adecuados para la implementaci√≥n en tiempo real en plataformas de alto rendimiento.18 Las plataformas de redes sociales generan grandes cantidades de datos cada segundo. Los sistemas de detecci√≥n del discurso de odio deben poder procesar estos datos de forma r√°pida y precisa para ser eficaces. Esto a menudo implica concesiones entre la complejidad, la precisi√≥n y la velocidad del modelo.

Conclusiones: La investigaci√≥n sobre la detecci√≥n del discurso de odio con aprendizaje autom√°tico ha experimentado una evoluci√≥n significativa, desde enfoques tempranos basados en reglas y diccionarios hasta el paradigma actual dominado por modelos de transformadores preentrenados. Si bien los avances t√©cnicos han permitido lograr resultados notables en la identificaci√≥n de contenido odioso, persisten desaf√≠os fundamentales. La dificultad para detectar formas sutiles de discurso de odio, como el sarcasmo y la iron√≠a, junto con la necesidad de distinguir entre el discurso expl√≠cito e impl√≠cito, subraya la complejidad inherente de la tarea. Adem√°s, la falta de generalizaci√≥n de los modelos a nuevos dominios y plataformas, los problemas de sesgo en los datos y los algoritmos, la necesidad de una mayor explicabilidad en las decisiones de los modelos y los desaf√≠os de la implementaci√≥n en tiempo real siguen siendo √°reas activas de investigaci√≥n. La diversidad de conjuntos de datos disponibles, aunque valiosa para explorar diferentes facetas del problema, tambi√©n contribuye a la dificultad de comparar resultados y establecer est√°ndares de evaluaci√≥n uniformes. En √∫ltima instancia, la detecci√≥n eficaz y √©tica del discurso de odio requiere un enfoque multidisciplinario que considere no solo los avances t√©cnicos en el aprendizaje autom√°tico y el procesamiento del lenguaje natural, sino tambi√©n las complejidades sociales, culturales y ling√º√≠sticas del fen√≥meno.

---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que realices el primer capitulo el cual es el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con ML a lo largo del tiempo hasta la fecha, que tecnicas se usaron, como fue la evolucion de estas tecnicas, modelos, sus metricas, desafios entre otros. ¬øQu√© t√©cnicas se usaban antes del auge del Machine Learning moderno?
¬øCu√°les fueron los primeros enfoques de Machine Learning aplicados al problema? (Probablemente modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, KNN, SGDClassifier, Random Forest), ¬øCuales son los enfoques mas actuales?. Representaci√≥n del Texto, Datasets Utilizados.

---
Podrias hacer cuadros comparativos entre las tecnicas usas en la diferentes secciones:


Un cuadro para: Aplicaciones Iniciales de Machine Learning Tradicional


Otro para: Integraci√≥n de Word Embeddings y Modelos Neuronales Simples


Otro para: Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n


Otro para: El Paradigma de los Modelos Pre-entrenados (Transformers).


El cuadro debe tener:


T√©cnica
Caracter√≠sticas
Modelos Comunes
M√©tricas y Resultados Notables

---

Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar (mayoritariamente arvix), aproximadamente 20 articulos o mas, y poder realizar el primer capitulo el cual sera el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con Machine Learning a lo largo del tiempo hasta la fecha, haciendo una especie de revision historica desde las tecnicas que se usaban en los inicios hasta las tecnicas que estan en vanguardia en la actualidad.

Toda la investigacion debe estar respaldada por articulos cientificos.

Aqu√≠ tienes una estructura para el Cap√≠tulo 1 (Estado del Arte):

1.1 Introducci√≥n al Cap√≠tulo
* Reafirma el prop√≥sito del cap√≠tulo: presentar una revisi√≥n exhaustiva y cr√≠tica de la investigaci√≥n existente sobre la detecci√≥n autom√°tica de discurso de odio utilizando t√©cnicas de Machine Learning.
* Indica que esta revisi√≥n servir√° para contextualizar el problema, identificar las aproximaciones previas, sus logros y limitaciones, y justificar la necesidad de futuras investigaciones y la propuesta que se presentar√° en cap√≠tulos posteriores.

1.2 Definiciones y Terminolog√≠a en la Literatura
* En lugar de dar tu definici√≥n de hate speech aqu√≠ (eso va en el Marco Te√≥rico), discute c√≥mo los investigadores en los art√≠culos revisados definen y abordan el concepto.
* Se√±ala la variabilidad en la terminolog√≠a (hate speech, offensive language, abusive language) y en las definiciones operacionales utilizadas en los estudios. Esto muestra una comprensi√≥n profunda de la complejidad del problema.

1.3 Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")
* Esta es la secci√≥n principal donde describes la trayectoria de la investigaci√≥n.
* No necesitas explicar qu√© es un SVM o un Transformer aqu√≠ (eso va en el Marco Te√≥rico). En cambio, describe c√≥mo se aplicaron al problema de la detecci√≥n de discurso de odio y qu√© resultados se obtuvieron.

1.3.1 Enfoques Tempranos y Basados en Reglas/Diccionarios 
* Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple.

1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional
* ¬øC√≥mo se usaron SVM, Naive Bayes, Regresion Logistica, entre otros relevantes? 
* ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos? 
(Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF).

1.3.3 Integraci√≥n de Word Embeddings y Modelos Neuronales Simples
* Describe el impacto de los embeddings y c√≥mo se combinaron con CNNs o RNNs b√°sicas y que limitaciones tenian.

1.3.4 Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n
* Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas y que mejoras implementan.

1.3.5 El Paradigma de los Modelos Pre-entrenados (Transformers)
*Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.

NOTA: Dentro de cada sub-secci√≥n, menciona los modelos espec√≠ficos aplicados, los datasets clave utilizados en esos trabajos particulares, las m√©tricas reportadas y los resultados obtenidos. Compara y contrasta si los art√≠culos lo permiten. Ademas realiza un cuadro comparativo en cada sub-seccion para comparar las diferentes tecnicas usadas.

1.4 Datasets y Desaf√≠os Asociados a los Datos
* Discute los principales datasets que aparecen en la literatura revisada.
* Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).
* Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.
* Ademas realiza un cuadro comparativo.

1.5 M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura
* Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.
* Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?
* Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.

1.6 Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")
* Esta secci√≥n es CRUCIAL para justificar tu propuesta.
* Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.
* Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.
* Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.


Realiza un informe detallado de cada uno de los puntos, el informe debe estar en un formato academico en espa√±ol siguiendo las normas APA haciendo un uso correcto de las referencias y respetando la estructura






Ahora podrias hacer cuadros comparativos entre las tecnicas usas en la diferentes secciones:


Un cuadro para: 1.3.2 Machine Learning Tradicional 

Otro para: 1.3.3 Word Embeddings y Modelos Neuronales Simples


Otro para: 1.3.4 LSTMs, GRUs y Mecanismos de Atenci√≥n

Otro para: 1.3.5 Modelos Pre-entrenados (Transformers como BERT, RoBERTa, LLMs)

Comparando asi las diferentes tecnicas en su correspondiente epoca, en vez de un solo cuadro general

Los cuadros deben tener:

T√©cnica
Caracter√≠sticas
Modelos Comunes
M√©tricas y Resultados Notables

Tambien podria incluir la referencia al estudio donde se sacaron tales resultados







-Conclusiones del Cap√≠tulo

* Resume brevemente los hallazgos clave de la revisi√≥n: la trayectoria del campo, las t√©cnicas m√°s destacadas, el estado actual, y reitera los principales desaf√≠os y las oportunidades de investigaci√≥n.

* Concluye indicando que el siguiente cap√≠tulo (Marco Te√≥rico) proporcionar√° los fundamentos te√≥ricos necesarios para comprender las bases de estos enfoques y la metodolog√≠a a seguir.
---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar (mayoritariamente arvix), aproximadamente 20 articulos, y poder realizar el primer capitulo el cual sera el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con Machine Learning a lo largo del tiempo hasta la fecha

Estos son los puntos ya realizados:

1.1 Introducci√≥n al Cap√≠tulo

1.2 Definiciones y Terminolog√≠a en la Literatura

1.3 Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")

1.3.1 Enfoques Tempranos y Basados en Reglas/Diccionarios

Ahora necesito que investigues el siguiente punto:

1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional
* ¬øC√≥mo se usaron SVM, Naive Bayes, Regresion Logistica, entre otros relevantes? (Centrate especificamente en articulos de modelos tradicionales de Machine Learning (como SVM, Naive Bayes, Regresi√≥n Log√≠stica, entre otros relevantes) en la detecci√≥n del discurso de odio o lenguaje ofensivo, no tomes en cuentas tecnicas mas avanzadas como transformers o redes neuronales, mecanismo de atencion ni la Integraci√≥n de Word Embeddings y Modelos Neuronales Simples ya que estas seran abordadas mas adelante.)
* ¬øCuales fueron sus mejoras con respecto a los enfoques anteriores?
* ¬øQu√© tipo de features (TF-IDF, n-grams) se usaban con ellos?
(Describe el uso de las features, no la explicaci√≥n matem√°tica de TF-IDF, esa parte se dejar√° para el marco teorico).
* ¬øQue limitaciones tenian?
* ¬øCuales son los resultados de los estudios?  
* Realiza un cuadro comparativo con las distintas tecnicas puede tener los siguiete puntos: 
-T√©cnica
-Caracter√≠sticas
-Modelos Comunes
-M√©tricas y Resultados Notables
A√±ade tambien o trata de integrar una seccion donde se especifiquen los estudios que se usaron para obtener ese cuadro comparativo.

Tambien puedes a√±adir otros aspecto o puntos que consideres importantes en cuanto a las Aplicaciones Iniciales de Machine Learning Tradicional

Todo el informe debe estar basado en articulos cientificos, preferiblemente de arvix y google scholar, respetando las reglas APA y en idioma espa√±ol.

---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar (mayoritariamente arvix), aproximadamente 20 articulos, y poder realizar el primer capitulo el cual sera el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con Machine Learning a lo largo del tiempo hasta la fecha

Estos son los puntos ya realizados:

1.1 Introducci√≥n al Cap√≠tulo

1.2 Definiciones y Terminolog√≠a en la Literatura

1.3 Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")

1.3.1 Enfoques Tempranos y Basados en Reglas/Diccionarios

Ahora necesito que investigues el siguiente punto:

1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional
* ¬øC√≥mo se usaron SVM, Naive Bayes, Regresion Logistica, entre otros relevantes? (Centrate especificamente en articulos con tecnicas tradicionales de Machine Learning (como BoW, n-grams, TF-IDF con modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, entre otros relevantes) en la detecci√≥n del discurso de odio o lenguaje ofensivo, no tomes en cuentas tecnicas mas avanzadas como transformers o redes neuronales, mecanismo de atencion ni la Integraci√≥n de Word Embeddings y Modelos Neuronales Simples ya que estas seran abordadas mas adelante.)
* ¬øQu√© tipo de features (BoW, n-grams, TF-IDF) se usaban con los modelos?
(Describe brevemente que son, sus diferencia y el uso de las features a modo de contexto para el lector, no la explicaci√≥n matem√°tica de TF-IDF o n-grams, esa parte se dejar√° para el marco teorico).
* ¬øCuales fueron sus mejoras con respecto a los enfoques anteriores?
* ¬øQue limitaciones tenian?
* ¬øCuales son los resultados de los estudios?  
* Realiza un cuadro comparativo con las distintas tecnicas puede tener los siguiete puntos: 
-T√©cnica de Representaci√≥n de Texto
-Caracter√≠sticas
-Modelo (hacerse la comparacion con varios modelos si es posible y existen los estudios para una misma tecnica)
-M√©tricas y Resultados Notables
A√±ade tambien o trata de integrar una seccion donde se especifiquen los estudios que se usaron para obtener ese cuadro comparativo.

Tambien puedes a√±adir otros aspecto o puntos que consideres importantes en cuanto a las Aplicaciones Iniciales de Machine Learning Tradicional
Todo el informe debe estar basado en articulos cientificos, preferiblemente de arvix y google scholar, respetando las reglas APA y en idioma espa√±ol.

---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), necesito que hagas una busqueda extensa de articulos en arxiv y google scholar (mayoritariamente arvix), aproximadamente 20 articulos, y poder realizar el primer capitulo el cual sera el estado del arte, donde se estara estudiando como se estuvo haciendo la deteccion del discurso de odio con Machine Learning a lo largo del tiempo hasta la fecha

Estos son los puntos ya realizados en mi informe:

1.1 Introducci√≥n al Cap√≠tulo

1.2 Definiciones y Terminolog√≠a en la Literatura

1.3 Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")

1.3.1 Enfoques Tempranos y Basados en Reglas/Diccionarios

1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional

1.3.2.2 T√©cnicas de Representaci√≥n de Texto (Feature Engineering, Bag of Words (BoW), N-gramas y TF-IDF)

1.3.2.3 Modelos de Machine Learning Tradicionales Aplicados (M√°quinas de Soporte Vectorial (SVM), Clasificador Bayesiano Ingenuo (Naive Bayes) y Regresi√≥n Log√≠stica (LR), a menudo complementados por otros modelos como √Årboles de Decisi√≥n (Decision Trees), K-Nearest Neighbors (KNN) y Random Forests (RF))

1.3.2.4 Mejoras y Limitaciones de las Aplicaciones Iniciales de Machine Learning Tradicional

1.3.2.5 Cuadro Comparativo y Resultados Notables

Ahora necesito que investigues los siguiente puntos:

1.3.3 Integraci√≥n de Word Embeddings y Modelos Neuronales Simples

* Describe el impacto de los embeddings (describe brevemente los embeddings sin dar un definicion extensa, ya que esta se hara en el marco teorico, en este punto no explores  mucho los mecanismos de atencion ni modelos mas avanzados, eso se dejara para el siguiente punto)
* C√≥mo se combinaron con CNNs o RNNs b√°sicas
* Mejoras y Limitaciones (Tratando de crear un sutil enlace para el lector entre las aplicaciones anteriores y las siguiente: Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n)
* Realiza un cuadro comparativo con las distintas tecnicas puede tener los siguiete puntos: 
-T√©cnica
-Caracter√≠sticas
-Modelo (hacerse la comparacion con varios modelos si es posible y existen los estudios para una misma tecnica)
-M√©tricas y Resultados Notables
A√±ade tambien o trata de integrar una seccion donde se especifiquen los estudios que se usaron para obtener ese cuadro comparativo.

Tambien puedes a√±adir otros aspecto o puntos que consideres importantes en cuanto a Integraci√≥n de Word Embeddings y Modelos Neuronales Simples

1.3.4 Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n

* Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas
* Como se combinaron con modelos mas avanzados
* Mejoras y Limitaciones (Tratando de crear un sutil enlace para el lector entre las aplicaciones del puntos anterior y las siguiente: El Paradigma de los Modelos Pre-entrenados (Transformers))
* Realiza un cuadro comparativo con las distintas tecnicas puede tener los siguiete puntos: 
-T√©cnica
-Caracter√≠sticas
-Modelo (hacerse la comparacion con varios modelos si es posible y existen los estudios para una misma tecnica)
-M√©tricas y Resultados Notables
A√±ade tambien o trata de integrar una seccion donde se especifiquen los estudios que se usaron para obtener ese cuadro comparativo.

Tambien puedes a√±adir otros aspecto o puntos que consideres importantes en cuanto a Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n

1.3.5 El Paradigma de los Modelos Pre-entrenados (Transformers)

*Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.
(Describe las tecnicas usado y los modelos, sin llegar a definiciones extensas, ya que eso se realizara en el capitulo del marco teorico)
* Mejoras y Limitaciones (Tratando de crear un sutil enlace para el lector entre las aplicaciones del puntos anterior y como llegaron a ser la vanguardia y que desafios experimientan para el futuro)
* Realiza un cuadro comparativo con las distintas tecnicas puede tener los siguiete puntos: 
-T√©cnica
-Caracter√≠sticas
-Modelo (hacerse la comparacion con varios modelos si es posible y existen los estudios para una misma tecnica)
-M√©tricas y Resultados Notables
A√±ade tambien o trata de integrar una seccion donde se especifiquen los estudios que se usaron para obtener ese cuadro comparativo.

Tambien puedes a√±adir otros aspecto o puntos que consideres importantes en cuanto a El Paradigma de los Modelos Pre-entrenados (Transformers)

Todo el informe debe estar basado en articulos cientificos, preferiblemente de arvix y google scholar, respetando las reglas APA y en idioma espa√±ol.




1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional
* ¬øC√≥mo se usaron SVM, Naive Bayes, Regresion Logistica, entre otros relevantes? (Centrate especificamente en articulos con tecnicas tradicionales de Machine Learning (como BoW, n-grams, TF-IDF con modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, entre otros relevantes) en la detecci√≥n del discurso de odio o lenguaje ofensivo, no tomes en cuentas tecnicas mas avanzadas como transformers o redes neuronales, mecanismo de atencion ni la Integraci√≥n de Word Embeddings y Modelos Neuronales Simples ya que estas seran abordadas mas adelante.)
* ¬øQu√© tipo de features (BoW, n-grams, TF-IDF) se usaban con los modelos?
(Describe brevemente que son, sus diferencia y el uso de las features a modo de contexto para el lector, no la explicaci√≥n matem√°tica de TF-IDF o n-grams, esa parte se dejar√° para el marco teorico).
* ¬øCuales fueron sus mejoras con respecto a los enfoques anteriores?
* ¬øQue limitaciones tenian?
* ¬øCuales son los resultados de los estudios?  

---
Soy estudiante de la universidad central de la UCV, estoy haciendo mi semario de Inteligencia artificial, sobre la deteccion del discurso de odio con Machine Learning, que va a tener 4 capitulos (Estado del arte, Marco Teorico, Marco Metodologico y Propuesta Trabajo Especial de Grado), al final se debe proponer una solucion al problema la cual ser√° desarrollada proximamente en la tesis.

La estructura hasta ahora de mi semanario en la siguiente, con el primer capitulo terminado:

Detecci√≥n Autom√°tica de Discurso de Odio y Leguaje Ofensivo

Cap√≠tulo 1: Estado del Arte 

1.1 Introducci√≥n al Cap√≠tulo
* Reafirma el prop√≥sito del cap√≠tulo: presentar una revisi√≥n exhaustiva y cr√≠tica de la investigaci√≥n existente sobre la detecci√≥n autom√°tica de discurso de odio utilizando t√©cnicas de Machine Learning.
* Indica que esta revisi√≥n servir√° para contextualizar el problema, identificar las aproximaciones previas, sus logros y limitaciones, y justificar la necesidad de futuras investigaciones y la propuesta que se presentar√° en cap√≠tulos posteriores.

1.2 Definiciones y Terminolog√≠a en la Literatura
* En lugar de dar tu definici√≥n de hate speech aqu√≠ (eso va en el Marco Te√≥rico), discute c√≥mo los investigadores en los art√≠culos revisados definen y abordan el concepto.
* Se√±ala la variabilidad en la terminolog√≠a (hate speech, offensive language, abusive language) y en las definiciones operacionales utilizadas en los estudios. Esto muestra una comprensi√≥n profunda de la complejidad del problema.

1.3 Evoluci√≥n de los Enfoques Metodol√≥gicos (El "C√≥mo se ha Hecho")
* Esta es la secci√≥n principal donde describes la trayectoria de la investigaci√≥n.
* No necesitas explicar qu√© es un SVM o un Transformer aqu√≠ (eso va en el Marco Te√≥rico). En cambio, describe c√≥mo se aplicaron al problema de la detecci√≥n de discurso de odio y qu√© resultados se obtuvieron.

1.3.1 Enfoques Tempranos y Basados en Reglas/Diccionarios 
* Describe los m√©todos m√°s antiguos y c√≥mo se hizo la transici√≥n a ML simple.

1.3.2 Aplicaciones Iniciales de Machine Learning Tradicional
* ¬øC√≥mo se usaron SVM, Naive Bayes, Regresion Logistica, entre otros relevantes? (Se centra especificamente en articulos con tecnicas tradicionales de Machine Learning (como BoW, n-grams, TF-IDF con modelos como SVM, Naive Bayes, Regresi√≥n Log√≠stica, entre otros relevantes) en la detecci√≥n del discurso de odio o lenguaje ofensivo.
* ¬øQu√© tipo de features (BoW, n-grams, TF-IDF) se usaban con los modelos?
(Describe el uso de las features con una breve descripcion, no la explicaci√≥n matem√°tica de TF-IDF o n-grams, esa parte se dejar√° para el marco teorico).
* ¬øCuales fueron sus mejoras con respecto a los enfoques anteriores?
* ¬øQue limitaciones tenian?
* ¬øCuales son los resultados de los estudios? 

1.3.4 Avances con LSTMs, GRUs y Mecanismos de Atenci√≥n
* Describe la aplicaci√≥n de arquitecturas neuronales m√°s avanzadas para capturar dependencias complejas y que mejoras implementan.

1.3.5 El Paradigma de los Modelos Pre-entrenados (Transformers)
*Describe c√≥mo modelos como BERT y sus variantes se aplican mediante fine-tuning para lograr resultados de vanguardia.

1.4 Datasets y Desaf√≠os Asociados a los Datos
* Discute los principales datasets que aparecen en la literatura revisada.
* Se√±ala las caracter√≠sticas importantes de estos datasets (fuente, idioma, tama√±o, esquema de etiquetado).
* Enf√≥cate en los desaf√≠os inherentes a los datos para este problema: el desbalance de clases (un punto muy importante), la subjetividad de la anotaci√≥n, la calidad de los datos, la evoluci√≥n del lenguaje, la necesidad de datos en diversos idiomas, etc.
* Ademas realiza un cuadro comparativo.

1.5 M√©tricas y Metodolog√≠as de Evaluaci√≥n en la Literatura
* Describe c√≥mo se mide el rendimiento de los modelos en los estudios revisados.
* Explica la importancia de las m√©tricas adecuadas (Precision, Recall, F1-score, AUC) dado el problema del desbalance de clases. ¬øPor qu√© Accuracy no es suficiente?
* Menciona si hay enfoques de evaluaci√≥n estandarizados o comparativas comunes.

1.6 Desaf√≠os Persistentes y Limitaciones de los Enfoques Existentes (El "Por Qu√© A√∫n No Est√° Resuelto")
* Esta secci√≥n es CRUCIAL para justificar tu propuesta.
* Sintetiza las limitaciones y dificultades que han enfrentado los investigadores a pesar de los avances t√©cnicos.
* Revisa los desaf√≠os ya mencionados en el punto anterior y ampl√≠a otros: la detecci√≥n de sarcasmo/iron√≠a, el discurso de odio impl√≠cito vs. expl√≠cito, la generalizaci√≥n a nuevos dominios/plataformas, los problemas de sesgo en los modelos, la explicabilidad de los resultados, los desaf√≠os de implementaci√≥n en tiempo real.
* Presenta estos desaf√≠os como brechas en la investigaci√≥n existente.

1.7 Tendencias Actuales y Direcciones Futuras (Enlace Directo a tu Propuesta)
* Basado en la revisi√≥n de los art√≠culos m√°s recientes y las discusiones en los "Future Work" de los autores, ¬øhacia d√≥nde se mueve el campo? (Ej: modelos multimodales, pocos-shot learning, detecci√≥n proactiva, enfoques √©ticos).
* Identifica CLARAMENTE las √°reas de investigaci√≥n que A√öN NECESITAN TRABAJO y que est√°n alineadas con lo que t√∫ propondr√°s en el Cap√≠tulo 4. Este es el puente expl√≠cito entre el Estado del Arte y tu Propuesta. Puedes decir algo como: "A pesar de los avances, la revisi√≥n de la literatura revela que X, Y y Z siguen siendo desaf√≠os abiertos, lo que justifica la necesidad de investigar enfoques como el propuesto en el Cap√≠tulo 4."

1.8 Conclusiones del Cap√≠tulo
* Resume brevemente los hallazgos clave de la revisi√≥n: la trayectoria del campo, las t√©cnicas m√°s destacadas, el estado actual, y reitera los principales desaf√≠os y las oportunidades de investigaci√≥n.
* Concluye indicando que el siguiente cap√≠tulo (Marco Te√≥rico) proporcionar√° los fundamentos te√≥ricos necesarios para comprender las bases de estos enfoques y la metodolog√≠a a seguir. 

Ahora necesito que des una estructura para armar mi segundo capitulo el marco teorico, para sustentar el primer capitulo

---
